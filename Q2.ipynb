{"cells":[{"cell_type":"code","execution_count":78,"metadata":{"executionInfo":{"elapsed":384,"status":"ok","timestamp":1650272556082,"user":{"displayName":"nova arunas","userId":"08494579974582739480"},"user_tz":-180},"id":"GrJWHuVbnld6"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def dataParser(x, y):\n","    xTrain, yTrain = open(x), open(y)\n","    feature = xTrain.readline().split(\",\")\n","    yTrain.readline()\n","    weight, ground = [], []\n","    for line in xTrain:\n","        L = line\n","        L = L.split(\",\")\n","        L = list(map(float, L))\n","        weight.append(L)\n","        ground.append(int(yTrain.readline()))\n","    xTrain.close()\n","    yTrain.close()\n","    return [feature, weight, ground]\n","\n","def comp_confmat(actual, predicted, comment = False):\n","    classes = np.unique(actual)\n","    confmat = np.zeros((len(classes), len(classes)))\n","    for i in range(len(classes)):\n","        for j in range(len(classes)):\n","           confmat[i, j] = np.sum((actual == classes[i]) & (predicted == classes[j]))\n","    [TP, FP], [FN, TN] = confmat\n","    Precision = TP/(TP+FP)\n","    Recall = TP/(TP+FN)\n","    Accuracy = (TP+TN)/len(predicted)\n","    Specificity = (TN)/(TN+FP)\n","    F_m = lambda B : (1+B**2)*Precision*Recall/(Precision*B**2+Recall)\n","    if comment:\n","        print(\"Wrong guesses:         {:.0f}\".format(FP+FN))\n","        print(\"Accuracy:              {:.5f}%\".format(Accuracy*100), end = \"\\t\")\n","        print(\"Precision:             {:.5f}%\".format(Precision*100))\n","        print(\"Recall:                {:.5f}%\".format(Recall*100), end = \"\\t\")\n","        print(\"Specificity:           {:.5f}%\".format(Specificity*100))\n","        print(f\"F-Measures(1, 2, 0.5): {F_m(1):.4f}, {F_m(2):.4f}, {F_m(0.5):.4f}\")\n","        print(\"Confusion Matrix:\\n\",confmat,\"\\n\")\n","    return confmat, [Accuracy, Precision, Recall, Specificity, F_m(2)]\n","\n","def sigmoid(x):\n","    return np.exp(-np.logaddexp(0, -x))\n","\n","def train(weights, samples, grounds, epoch, gamma):\n","    weights = weights.copy()\n","    for i in range(epoch):\n","        Z = weights[0] + np.dot(weights[1:],samples.T)\n","        mcle = 1 - sigmoid(-Z) #Y = 1 | X,w for each sample\n","        cached = samples * (grounds - mcle)[:, None]\n","        weights = weights.copy() + gamma*np.insert(np.sum(cached, axis = 0), 0, 1)\n","    return weights\n","\n","def trainMiniBatch(weights, trainSamples, trainGrounds, epoch, gamma, batchSize = 32, seed = None):\n","    weights = weights.copy()\n","    accuracyList = []\n","    if type(seed) == int: np.random.seed(seed)\n","    for i in range(epoch):\n","        permutation = list(np.random.permutation(len(trainGrounds)))\n","        shuffled_samples = trainSamples[permutation]\n","        shuffled_grounds = trainGrounds[permutation]\n","        samples = [shuffled_samples[i::batchSize] for i in range(batchSize)]\n","        grounds = [shuffled_grounds[i::batchSize] for i in range(batchSize)]\n","        estimates = []\n","        for j in range(batchSize):\n","            Z = weights[0] + np.dot(weights[1:],samples[j].T)\n","            mcle = 1 - sigmoid(-Z) #Y = 1 | X,w for each sample\n","            cached = samples[j] * (grounds[j] - mcle)[:, None]\n","            weights = weights.copy() + gamma*np.insert(np.sum(cached, axis = 0), 0, 1)\n","            estimates.extend(np.heaviside(mcle - 0.5, 1))\n","        falses = np.count_nonzero(np.array(estimates)-np.concatenate(grounds).ravel())\n","        accuracyList.append([1-falses/len(estimates) , i])\n","    return weights, np.array(accuracyList).T\n","\n","def trainStochastic(weights, trainSamples, trainGrounds, epoch, gamma):\n","    weights = weights.copy()\n","    for i in range(epoch):\n","        permutation = list(np.random.permutation(len(trainGrounds)))\n","        shuffled_samples = trainSamples[permutation]\n","        shuffled_grounds = trainGrounds[permutation]\n","        for j in range(len(shuffled_samples)):\n","            Z = weights[0] + np.dot(weights[1:],shuffled_samples[j].T)\n","            mcle = 1 - sigmoid(-Z) #Y = 1 | X,w for each sample\n","            weights = weights.copy() + gamma*np.insert(shuffled_samples[j] * (shuffled_grounds[j] - mcle), 0, 1)\n","    return weights\n","\n","def normalizeData(samples, normal):\n","    features = normal.copy().T\n","    data = samples.copy().T\n","    for i in range(len(features)):\n","        xMin = features[i].min()\n","        xMax = features[i].max()\n","        data[i] = (data[i].copy() - xMin)/(xMax - xMin)\n","    return data.T\n","\n","def forward(weights, testSamples, comment = True):\n","    Z = weights[0] + np.dot(weights[1:],testSamples.T)\n","    mcle = 1 - sigmoid(-Z) #Y = 1 | X,w for each sample\n","    estimate = np.heaviside(mcle - 0.5, 1)\n","    return comp_confmat(test_ground, estimate, comment=comment)\n","\n","def plotParameter(parameters, metric, labels):\n","        x_labels = [labels[0]+' = {}'.format(parameter) for parameter in parameters]\n","        for idx in range(len(metric)):\n","            plt.plot(x_labels, metric[idx], marker='o', markersize=6, linewidth=2, label=labels[1+idx])\n","        plt.title('Parameter vs Metrics Plot')\n","        plt.xlabel('Changing Parameter')\n","        plt.ylabel('% Metric')\n","        plt.legend()\n","        plt.show()"]},{"cell_type":"code","execution_count":54,"metadata":{"executionInfo":{"elapsed":2563,"status":"ok","timestamp":1650270853594,"user":{"displayName":"nova arunas","userId":"08494579974582739480"},"user_tz":-180},"id":"X_QdsrUDnld-"},"outputs":[],"source":["[features, samples, grounds] = dataParser(\"q2_train_samples.csv\", \"q2_train_labels.csv\")\n","test_parse = dataParser(\"q2_test_samples.csv\", \"q2_test_labels.csv\")\n","test_samples, test_ground = np.array(test_parse[1], dtype = float), np.array(test_parse[2], dtype = int)\n","samples = np.array(samples, dtype = float)\n","test_samples = normalizeData(test_samples, samples)\n","samples = normalizeData(samples, samples)\n","grounds = np.array(grounds, dtype = int)\n","weights = np.random.normal(0, 0.01, (len(features) + 1))\n","run = 1"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":436,"status":"ok","timestamp":1649668090804,"user":{"displayName":"nova arunas","userId":"08494579974582739480"},"user_tz":-180},"id":"HODz5r3Unld-","outputId":"d4dcb739-d39b-40c8-8045-b37dcc9541af"},"outputs":[{"name":"stdout","output_type":"stream","text":["Learning Rate: 0.0001\n","Wrong guesses:         55\n","Accuracy:              74.77064%\tPrecision:             99.19355%\n","Recall:                69.49153%\tSpecificity:           97.56098%\n","F-Measures(1, 2, 0.5): 0.8173, 0.7392, 0.9138\n","Confusion Matrix:\n"," [[123.   1.]\n"," [ 54.  40.]] \n","\n","Learning Rate: 0.0002\n","Wrong guesses:         40\n","Accuracy:              81.65138%\tPrecision:             99.19355%\n","Recall:                75.92593%\tSpecificity:           98.21429%\n","F-Measures(1, 2, 0.5): 0.8601, 0.7966, 0.9347\n","Confusion Matrix:\n"," [[123.   1.]\n"," [ 39.  55.]] \n","\n","Learning Rate: 0.001\n","Wrong guesses:         21\n","Accuracy:              90.36697%\tPrecision:             99.19355%\n","Recall:                86.01399%\tSpecificity:           98.66667%\n","F-Measures(1, 2, 0.5): 0.9213, 0.8836, 0.9624\n","Confusion Matrix:\n"," [[123.   1.]\n"," [ 20.  74.]] \n","\n","Learning Rate: 0.0013021\n","Wrong guesses:         17\n","Accuracy:              92.20183%\tPrecision:             93.54839%\n","Recall:                92.80000%\tSpecificity:           91.39785%\n","F-Measures(1, 2, 0.5): 0.9317, 0.9295, 0.9340\n","Confusion Matrix:\n"," [[116.   8.]\n"," [  9.  85.]] \n","\n","Learning Rate: 0.002\n","Wrong guesses:         54\n","Accuracy:              75.22936%\tPrecision:             59.67742%\n","Recall:                94.87179%\tSpecificity:           64.28571%\n","F-Measures(1, 2, 0.5): 0.7327, 0.8486, 0.6446\n","Confusion Matrix:\n"," [[74. 50.]\n"," [ 4. 90.]] \n","\n","Learning Rate: 0.005\n","Wrong guesses:         19\n","Accuracy:              91.28440%\tPrecision:             99.19355%\n","Recall:                87.23404%\tSpecificity:           98.70130%\n","F-Measures(1, 2, 0.5): 0.9283, 0.8939, 0.9655\n","Confusion Matrix:\n"," [[123.   1.]\n"," [ 18.  76.]] \n","\n","Learning Rate: 0.05\n","Wrong guesses:         48\n","Accuracy:              77.98165%\tPrecision:             64.51613%\n","Recall:                95.23810%\tSpecificity:           67.16418%\n","F-Measures(1, 2, 0.5): 0.7692, 0.8696, 0.6897\n","Confusion Matrix:\n"," [[80. 44.]\n"," [ 4. 90.]] \n","\n","Learning Rate: 0.5\n","Wrong guesses:         64\n","Accuracy:              70.64220%\tPrecision:             100.00000%\n","Recall:                65.95745%\tSpecificity:           100.00000%\n","F-Measures(1, 2, 0.5): 0.7949, 0.7078, 0.9064\n","Confusion Matrix:\n"," [[124.   0.]\n"," [ 64.  30.]] \n","\n","Learning Rate: 1\n","Wrong guesses:         40\n","Accuracy:              81.65138%\tPrecision:             99.19355%\n","Recall:                75.92593%\tSpecificity:           98.21429%\n","F-Measures(1, 2, 0.5): 0.8601, 0.7966, 0.9347\n","Confusion Matrix:\n"," [[123.   1.]\n"," [ 39.  55.]] \n","\n","Learning Rate: 2\n","Wrong guesses:         33\n","Accuracy:              84.86239%\tPrecision:             99.19355%\n","Recall:                79.35484%\tSpecificity:           98.41270%\n","F-Measures(1, 2, 0.5): 0.8817, 0.8266, 0.9447\n","Confusion Matrix:\n"," [[123.   1.]\n"," [ 32.  62.]] \n","\n"]}],"source":["#batch gradient descent\n","%matplotlib qt\n","lr = [0.0001,0.0002, 0.001, 0.0013021, 0.002, 0.005, 0.05, 0.5, 1, 2]\n","metrics = np.zeros((2,len(lr)))\n","for i in range(len(lr)):\n","    weights = np.random.normal(0, 0.01, (len(features) + 1))\n","    print(\"Learning Rate:\",lr[i])\n","    weights = train(weights, samples, grounds, 40, lr[i])\n","    metrics[0,i],_,_,_,metrics[1,i] = forward(weights, test_samples)[1]\n","plotParameter(lr, metrics, [\"LR\",\"Accuracy Trial \"+str(run),\"F_2 Trial \"+str(run)])\n","run += 1"]},{"cell_type":"code","execution_count":142,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"executionInfo":{"elapsed":512,"status":"error","timestamp":1650272572827,"user":{"displayName":"nova arunas","userId":"08494579974582739480"},"user_tz":-180},"id":"uAAMYxNlevqV","outputId":"eb488b81-a901-40bb-9d00-c177bac372ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["Learning Rate: 5e-05\n","Wrong guesses:         69\n","Accuracy:              68.34862%\tPrecision:             100.00000%\n","Recall:                64.24870%\tSpecificity:           100.00000%\n","F-Measures(1, 2, 0.5): 0.7823, 0.6920, 0.8999\n","Confusion Matrix:\n"," [[124.   0.]\n"," [ 69.  25.]] \n","\n","Learning Rate: 0.0001\n","Wrong guesses:         52\n","Accuracy:              76.14679%\tPrecision:             99.19355%\n","Recall:                70.68966%\tSpecificity:           97.72727%\n","F-Measures(1, 2, 0.5): 0.8255, 0.7500, 0.9179\n","Confusion Matrix:\n"," [[123.   1.]\n"," [ 51.  43.]] \n","\n","Learning Rate: 0.0002\n","Wrong guesses:         39\n","Accuracy:              82.11009%\tPrecision:             99.19355%\n","Recall:                76.39752%\tSpecificity:           98.24561%\n","F-Measures(1, 2, 0.5): 0.8632, 0.8008, 0.9361\n","Confusion Matrix:\n"," [[123.   1.]\n"," [ 38.  56.]] \n","\n","Learning Rate: 0.005\n","Wrong guesses:         16\n","Accuracy:              92.66055%\tPrecision:             99.19355%\n","Recall:                89.13043%\tSpecificity:           98.75000%\n","F-Measures(1, 2, 0.5): 0.9389, 0.9098, 0.9700\n","Confusion Matrix:\n"," [[123.   1.]\n"," [ 15.  79.]] \n","\n","Learning Rate: 0.048\n","Wrong guesses:         18\n","Accuracy:              91.74312%\tPrecision:             91.93548%\n","Recall:                93.44262%\tSpecificity:           89.58333%\n","F-Measures(1, 2, 0.5): 0.9268, 0.9314, 0.9223\n","Confusion Matrix:\n"," [[114.  10.]\n"," [  8.  86.]] \n","\n","Learning Rate: 0.05\n","Wrong guesses:         13\n","Accuracy:              94.03670%\tPrecision:             98.38710%\n","Recall:                91.72932%\tSpecificity:           97.64706%\n","F-Measures(1, 2, 0.5): 0.9494, 0.9299, 0.9698\n","Confusion Matrix:\n"," [[122.   2.]\n"," [ 11.  83.]] \n","\n","Learning Rate: 0.055\n","Wrong guesses:         14\n","Accuracy:              93.57798%\tPrecision:             95.96774%\n","Recall:                92.96875%\tSpecificity:           94.44444%\n","F-Measures(1, 2, 0.5): 0.9444, 0.9355, 0.9535\n","Confusion Matrix:\n"," [[119.   5.]\n"," [  9.  85.]] \n","\n","Learning Rate: 1\n","Wrong guesses:         14\n","Accuracy:              93.57798%\tPrecision:             95.96774%\n","Recall:                92.96875%\tSpecificity:           94.44444%\n","F-Measures(1, 2, 0.5): 0.9444, 0.9355, 0.9535\n","Confusion Matrix:\n"," [[119.   5.]\n"," [  9.  85.]] \n","\n","Learning Rate: 2\n","Wrong guesses:         87\n","Accuracy:              60.09174%\tPrecision:             29.83871%\n","Recall:                100.00000%\tSpecificity:           51.93370%\n","F-Measures(1, 2, 0.5): 0.4596, 0.6801, 0.3471\n","Confusion Matrix:\n"," [[37. 87.]\n"," [ 0. 94.]] \n","\n","Learning Rate: 3\n","Wrong guesses:         16\n","Accuracy:              92.66055%\tPrecision:             93.54839%\n","Recall:                93.54839%\tSpecificity:           91.48936%\n","F-Measures(1, 2, 0.5): 0.9355, 0.9355, 0.9355\n","Confusion Matrix:\n"," [[116.   8.]\n"," [  8.  86.]] \n","\n"]}],"source":["#mini-batch gradient descent\n","%matplotlib qt\n","lr = [0.00005,0.0001,0.0002, 0.005, 0.01, 0.05, 0.5, 1, 2, 3]\n","metrics = np.zeros((2,len(lr)))\n","for i in range(len(lr)):\n","    weights = np.random.normal(0, 0.01, (len(features) + 1))\n","    print(\"Learning Rate:\",lr[i])\n","    weights, _ = trainMiniBatch(weights, samples, grounds, 40, lr[i])\n","    metrics[0,i],_,_,_,metrics[1,i] = forward(weights, test_samples)[1]\n","plotParameter(lr, metrics, [\"LR\",\"Accuracy Trial \"+str(run),\"F_2 Trial \"+str(run)])\n","run += 1"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"56crQlTJevqW","outputId":"8f99697a-20af-4de1-ab49-01755004c65f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Learning Rate: 5e-05\n","Wrong guesses:         18\n","Accuracy:              91.74312%\tPrecision:             95.16129%\n","Recall:                90.76923%\tSpecificity:           93.18182%\n","F-Measures(1, 2, 0.5): 0.9291, 0.9161, 0.9425\n","Confusion Matrix:\n"," [[118.   6.]\n"," [ 12.  82.]] \n","\n","Learning Rate: 0.0001\n","Wrong guesses:         17\n","Accuracy:              92.20183%\tPrecision:             99.19355%\n","Recall:                88.48921%\tSpecificity:           98.73418%\n","F-Measures(1, 2, 0.5): 0.9354, 0.9044, 0.9685\n","Confusion Matrix:\n"," [[123.   1.]\n"," [ 16.  78.]] \n","\n","Learning Rate: 0.0002\n","Wrong guesses:         16\n","Accuracy:              92.66055%\tPrecision:             99.19355%\n","Recall:                89.13043%\tSpecificity:           98.75000%\n","F-Measures(1, 2, 0.5): 0.9389, 0.9098, 0.9700\n","Confusion Matrix:\n"," [[123.   1.]\n"," [ 15.  79.]] \n","\n","Learning Rate: 0.001\n","Wrong guesses:         23\n","Accuracy:              89.44954%\tPrecision:             91.12903%\n","Recall:                90.40000%\tSpecificity:           88.17204%\n","F-Measures(1, 2, 0.5): 0.9076, 0.9054, 0.9098\n","Confusion Matrix:\n"," [[113.  11.]\n"," [ 12.  82.]] \n","\n","Learning Rate: 0.005\n","Wrong guesses:         49\n","Accuracy:              77.52294%\tPrecision:             69.35484%\n","Recall:                88.65979%\tSpecificity:           68.59504%\n","F-Measures(1, 2, 0.5): 0.7783, 0.8398, 0.7251\n","Confusion Matrix:\n"," [[86. 38.]\n"," [11. 83.]] \n","\n","Learning Rate: 0.05\n","Wrong guesses:         52\n","Accuracy:              76.14679%\tPrecision:             66.93548%\n","Recall:                88.29787%\tSpecificity:           66.93548%\n","F-Measures(1, 2, 0.5): 0.7615, 0.8300, 0.7034\n","Confusion Matrix:\n"," [[83. 41.]\n"," [11. 83.]] \n","\n","Learning Rate: 0.5\n","Wrong guesses:         51\n","Accuracy:              76.60550%\tPrecision:             67.74194%\n","Recall:                88.42105%\tSpecificity:           67.47967%\n","F-Measures(1, 2, 0.5): 0.7671, 0.8333, 0.7107\n","Confusion Matrix:\n"," [[84. 40.]\n"," [11. 83.]] \n","\n","Learning Rate: 1\n","Wrong guesses:         47\n","Accuracy:              78.44037%\tPrecision:             70.96774%\n","Recall:                88.88889%\tSpecificity:           69.74790%\n","F-Measures(1, 2, 0.5): 0.7892, 0.8462, 0.7395\n","Confusion Matrix:\n"," [[88. 36.]\n"," [11. 83.]] \n","\n"]}],"source":["#stochastic gradient descent\n","%matplotlib qt\n","lr = [0.00005,0.0001,0.0002 ,0.001, 0.005, 0.05, 0.5, 1]\n","metrics = np.zeros((2,len(lr)))\n","for i in range(len(lr)):\n","    weights = np.random.normal(0, 0.01, (len(features) + 1))\n","    print(\"Learning Rate:\",lr[i])\n","    weights = trainStochastic(weights, samples, grounds, 40, lr[i])\n","    metrics[0,i],_,_,_,metrics[1,i] = forward(weights, test_samples)[1]\n","plotParameter(lr, metrics, [\"LR\",\"Accuracy Trial \"+str(run),\"F_2 Trial \"+str(run)])\n","run += 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":633,"status":"ok","timestamp":1649668099232,"user":{"displayName":"nova arunas","userId":"08494579974582739480"},"user_tz":-180},"id":"ZREOWKllnld_","outputId":"45431753-cc90-42f3-e2cd-f5d1da4f2e46"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wrong guesses:         16\n","Accuracy:              92.66055%\tPrecision:             94.35484%\n","Recall:                92.85714%\tSpecificity:           92.39130%\n","F-Measures(1, 2, 0.5): 0.9360, 0.9315, 0.9405\n","Confusion Matrix:\n"," [[117.   7.]\n"," [  9.  85.]] \n","\n"]}],"source":["#batch gradient descent with best learning rate\n","weights = np.random.normal(0, 0.01, (len(features) + 1))\n","weights = train(weights, samples, grounds, 40, 0.0013021)\n","_, _ = forward(weights, test_samples)"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"oVsOcesvevqW","outputId":"bc3e9e15-e27f-4632-be0c-66dc262cae46"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wrong guesses:         13\n","Accuracy:              94.03670%\tPrecision:             98.38710%\n","Recall:                91.72932%\tSpecificity:           97.64706%\n","F-Measures(1, 2, 0.5): 0.9494, 0.9299, 0.9698\n","Confusion Matrix:\n"," [[122.   2.]\n"," [ 11.  83.]] \n","\n"]}],"source":["#mini-batch gradient descent with best learning rate\n","weights = np.random.normal(0, 0.01, (len(features) + 1))\n","weights, _ = trainMiniBatch(weights, samples, grounds, 40, 0.05)\n","_, _ = forward(weights, test_samples)"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"5vEvIaXQevqW","outputId":"9e674424-37e3-4601-f6e7-f83631432923"},"outputs":[{"name":"stdout","output_type":"stream","text":["Wrong guesses:         16\n","Accuracy:              92.66055%\tPrecision:             99.19355%\n","Recall:                89.13043%\tSpecificity:           98.75000%\n","F-Measures(1, 2, 0.5): 0.9389, 0.9098, 0.9700\n","Confusion Matrix:\n"," [[123.   1.]\n"," [ 15.  79.]] \n","\n"]}],"source":["#stochastic gradient descent with best learning rate\n","weights = np.random.normal(0, 0.01, (len(features) + 1))\n","weights = trainStochastic(weights, samples, grounds, 40, 0.0002)\n","_, _ = forward(weights, test_samples)"]},{"cell_type":"code","execution_count":80,"metadata":{"id":"9hDAcr6YevqX","outputId":"3afbfe85-74ea-422f-d500-ce6728462132"},"outputs":[{"name":"stdout","output_type":"stream","text":["Random Distribution Metrics\n","Wrong guesses:         11\n","Accuracy:              94.95413%\tPrecision:             98.38710%\n","Recall:                93.12977%\tSpecificity:           97.70115%\n","F-Measures(1, 2, 0.5): 0.9569, 0.9414, 0.9729\n","Confusion Matrix:\n"," [[122.   2.]\n"," [  9.  85.]] \n","\n","Uniform Distribution Metrics\n","Wrong guesses:         11\n","Accuracy:              94.95413%\tPrecision:             98.38710%\n","Recall:                93.12977%\tSpecificity:           97.70115%\n","F-Measures(1, 2, 0.5): 0.9569, 0.9414, 0.9729\n","Confusion Matrix:\n"," [[122.   2.]\n"," [  9.  85.]] \n","\n","Zeros Distribution Metrics\n","Wrong guesses:         11\n","Accuracy:              94.95413%\tPrecision:             98.38710%\n","Recall:                93.12977%\tSpecificity:           97.70115%\n","F-Measures(1, 2, 0.5): 0.9569, 0.9414, 0.9729\n","Confusion Matrix:\n"," [[122.   2.]\n"," [  9.  85.]] \n","\n"]}],"source":["#mini-batch gradient descent with different initializations of weights\n","%matplotlib qt\n","initials = [ np.random.normal(0, 0.01, (len(features) + 1)),\n","            np.ones((len(features) + 1)),\n","            np.zeros((len(features) + 1))]\n","colorLegend = [['Random','skyblue',8],['Uniform','orange',6],['Zeros','red',4]]\n","for idx in range(len(initials)):\n","    weights = initials[idx]\n","    weights, accuracy = trainMiniBatch(weights, samples, grounds, 40, 0.05, seed = 1)\n","    print(colorLegend[idx][0], \"Distribution Metrics\")\n","    _, _ = forward(weights, test_samples)\n","    #plot\n","    plt.plot(accuracy[1], accuracy[0], marker='o', color=colorLegend[idx][1], label=colorLegend[idx][0], markersize=colorLegend[idx][2], linewidth=0)\n","plt.title('Accuracy vs Epoch')\n","plt.xlabel('Epoch')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.show()"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Q2.ipynb","provenance":[]},"interpreter":{"hash":"5bb7995976ccf47b4720b93d8141639533f85a21e36bd8fa4a25402a3173f53f"},"kernelspec":{"display_name":"Python 3.7.4 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
